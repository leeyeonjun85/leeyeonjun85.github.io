{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python OCR\n",
    "- 파이썬에서 사용되는 OCR 라이브러리들 테스트 하기\n",
    "\n",
    "## OCR 라이브러리\n",
    "> - paddleocr\n",
    "> - pytesseract\n",
    "> - CRAFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRAFT\n",
    "https://github.com/clovaai/CRAFT-pytorch/blob/master/test.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from uuid import getnode\n",
    "import socket\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import base64\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\leeyeonjun\\\\gitRepository\\\\leeyeonjun85.github.io.git\\\\assets\\\\source\\\\CRAFT-pytorch-master'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import craft_utils\n",
    "import imgproc\n",
    "import file_utils\n",
    "import json\n",
    "import zipfile\n",
    "from collections import OrderedDict\n",
    "from craft import CRAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyStateDict(state_dict):\n",
    "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = \".\".join(k.split(\".\")[start_idx:])\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CRAFT()     # initialize\n",
    "trained_model = 'C:/leeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/weights/craft_mlt_25k.pth'\n",
    "net.load_state_dict(copyStateDict(torch.load(trained_model, map_location='cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(img_dir):\n",
    "    imgs, masks, xmls = list_files(img_dir)\n",
    "    return imgs, masks, xmls\n",
    "\n",
    "def list_files(in_path):\n",
    "    img_files = []\n",
    "    mask_files = []\n",
    "    gt_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
    "        for file in filenames:\n",
    "            filename, ext = os.path.splitext(file)\n",
    "            ext = str.lower(ext)\n",
    "            if ext == '.jpg' or ext == '.jpeg' or ext == '.gif' or ext == '.png' or ext == '.pgm':\n",
    "                img_files.append(os.path.join(dirpath, file))\n",
    "            elif ext == '.bmp':\n",
    "                mask_files.append(os.path.join(dirpath, file))\n",
    "            elif ext == '.xml' or ext == '.gt' or ext == '.txt':\n",
    "                gt_files.append(os.path.join(dirpath, file))\n",
    "            elif ext == '.zip':\n",
    "                continue\n",
    "    # img_files.sort()\n",
    "    # mask_files.sort()\n",
    "    # gt_files.sort()\n",
    "    return img_files, mask_files, gt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CRAFT Text Detection')\n",
    "parser.add_argument('--trained_model', default='weights/craft_mlt_25k.pth', type=str, help='pretrained model')\n",
    "parser.add_argument('--text_threshold', default=0.7, type=float, help='text confidence threshold')\n",
    "parser.add_argument('--low_text', default=0.4, type=float, help='text low-bound score')\n",
    "parser.add_argument('--link_threshold', default=0.4, type=float, help='link confidence threshold')\n",
    "parser.add_argument('--cuda', default=True, type=str2bool, help='Use cuda for inference')\n",
    "parser.add_argument('--canvas_size', default=1280, type=int, help='image size for inference')\n",
    "parser.add_argument('--mag_ratio', default=1.5, type=float, help='image magnification ratio')\n",
    "parser.add_argument('--poly', default=False, action='store_true', help='enable polygon type')\n",
    "parser.add_argument('--show_time', default=False, action='store_true', help='show processing time')\n",
    "parser.add_argument('--test_folder', default='/data/', type=str, help='folder path to input images')\n",
    "parser.add_argument('--refine', default=False, action='store_true', help='enable link refiner')\n",
    "parser.add_argument('--refiner_model', default='weights/craft_refiner_CTW1500.pth', type=str, help='pretrained refiner model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_size = 1280\n",
    "mag_ratio = 1.5\n",
    "show_time = False\n",
    "text_threshold = 0.7\n",
    "link_threshold = 0.4\n",
    "low_text = 0.4\n",
    "cuda = False\n",
    "poly = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # resize\n",
    "    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n",
    "    ratio_h = ratio_w = 1 / target_ratio\n",
    "\n",
    "    # preprocessing\n",
    "    x = imgproc.normalizeMeanVariance(img_resized)\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
    "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
    "    if cuda:\n",
    "        x = x.cuda()\n",
    "\n",
    "    # forward pass\n",
    "    with torch.no_grad():\n",
    "        y, feature = net(x)\n",
    "\n",
    "    # make score and link map\n",
    "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
    "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
    "\n",
    "    # refine link\n",
    "    if refine_net is not None:\n",
    "        with torch.no_grad():\n",
    "            y_refiner = refine_net(y, feature)\n",
    "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
    "\n",
    "    t0 = time.time() - t0\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Post-processing\n",
    "    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
    "\n",
    "    # coordinate adjustment\n",
    "    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
    "    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
    "    for k in range(len(polys)):\n",
    "        if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "    t1 = time.time() - t1\n",
    "\n",
    "    # render results (optional)\n",
    "    render_img = score_text.copy()\n",
    "    render_img = np.hstack((render_img, score_link))\n",
    "    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n",
    "\n",
    "    if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
    "\n",
    "    return boxes, polys, ret_score_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = 'C:/leeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/img'\n",
    "image_list, _, _ = get_files(imgPath)\n",
    "result_folder = 'C:/leeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 0.0sleeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/img\\sqlite-sample-database-color.jpg0px.png\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "# load data\n",
    "for k, image_path in enumerate(image_list):\n",
    "    print(\"Test image {:d}/{:d}: {:s}\".format(k+1, len(image_list), image_path), end='\\r')\n",
    "    image = imgproc.loadImage(image_path)\n",
    "\n",
    "    bboxes, polys, score_text = test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly)\n",
    "\n",
    "    # save score text\n",
    "    filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "    mask_file = result_folder + \"/res_\" + filename + '_mask.jpg'\n",
    "    cv2.imwrite(mask_file, score_text)\n",
    "\n",
    "    file_utils.saveResult(image_path, image[:,:,::-1], polys, dirname=result_folder)\n",
    "\n",
    "print(\"elapsed time : {}s\".format(time.time() - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'C:/leeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/img/KakaoTalk_20240402_131936278.png'\n",
    "image_path = 'C:/leeyeonjun/gitRepository/leeyeonjun85.github.io.git/assets/source/CRAFT-pytorch-master/img/testBmp1.bmp'\n",
    "image = imgproc.loadImage(image_path)\n",
    "\n",
    "bboxes, polys, score_text = test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename, file_ext = os.path.splitext(os.path.basename(image_path))\n",
    "mask_file = result_folder + \"/res_\" + filename + '_mask.jpg'\n",
    "cv2.imwrite(mask_file, score_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헬로월드\n"
     ]
    }
   ],
   "source": [
    "print(\"헬로월드\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
