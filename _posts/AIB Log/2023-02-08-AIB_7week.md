---
title: "AI 부트캠프 7주 : Applied Predictive Modeling"
excerpt: "코드스테이츠와 함께하는 'AI 부트캠프' 7주차 회고"

categories:
  - AIB Log

tags:
  - 개발일지
  - 코딩
  - AI 부트캠프
  - 코드스테이츠

use_math: true

header:
  teaser: /assets/images/aib/codestates-ci.png

last_modified_at: 2023-02-08
---

<br><br><br><br>

![image]({{ site.url }}{{ site.baseurl }}/assets\images\aib\important-2508605_1920.jpg){: .align-center width="80%"}  

<br><br><br><br>




# 코드스테이츠와 함께하는 'AI 부트캠프' 7주차




<br><br><br><br>

## 주간회고
{: style="text-align: center;"}

<br><br><br><br>




### 더 공부가 필요한 부분
> 강의에서 배운 모델과 해석방법, 시각화 밖에도 어떠한 방법들이 있는지 알아보겠다.

### 5F 회고
- 사실(Fact)  
특성으로 모델을 해석하는 방법, 특히 모델이 타겟을 어떻게 예측하는지를 시각화하고 해석하는 방법에 대하여 학습하였다.

- 느낌(Feeling)  
그림그리기를 예로 들면, 모델의 성능을 높이는 과정이 얼마나 정교하게 스케치를 하는가였다면, 모델을 해석하는 과정은 그림에 색깔을 입히는 과정으로 느껴졌다. 모델을 어떻게 해석하는지에 따라서 모델의 색깔이 바뀌는 느낌?!

- 교훈(Finding)  
데이터분석의 궁극적인 목적이 인사이트를 얻는 것이라고 한다면 모델을 해석하는 것이야말로 데이터분석의 핵심이라고 할 수 있는 것 같다.

- 향후 행동(Future action)  
모델의 성능을 높이는 것 뿐만 아니라 모델이 무엇을 말하고자 하는지, 모델을 해석하는 과정도 중요하게 다루어야겠다.
- 피드백(Feedback) 




<br><br><br><br>

## N231 : Interpretable ML - I
{: style="text-align: center;"}

<br><br><br><br>




### 학습 목표🚩
- 🌱 Level 1 : Lecture Note 에 있는 주요 개념을 설명할 수 있으며 예제 코드를 이해하고 응용하여 과제를 수행할 수 있다.
  - Feature Importance
    - MDI 기반 Feature Importance에 대해 이해하고, 장점 및 단점을 설명할 수 있다.

  - Permutation Importance
    - Permutation Importance를 통해 Drop-Column Importance의 문제점을 어떻게 해결할 수 있는지 이해한다.
    - Permutaiton Importance의 장점 및 단점을 설명할 수 있다.
    - eli5 라이브러리를 사용하여 Permutation Importance를 계산하고 시각화할 수 있다.
    - Permutation Importance를 통해 중요한 특성들만 선택하여 모델을 학습할 수 있다.

- 🔝 Level 2 : Lecture Note 에 있는 개념 중 자신이 모르는 것을 구분해 낼 수 있으며 메타인지를 기반으로 자기 학습 계획을 세울 수 있다.
  - 오늘 배운 내용 중 아는 개념과 모르는 개념을 구분해서 readme.md 에 기록할 수 있다.
  → N231 노트 마무리 학습 후 아래 질문에 답해보세요의 질문에 답을 해보고 추가 학습이 필요한 질문을 기록할 수 있다.
  - 이후에 모르는 개념을 학습하기 위해 추가 학습 계획을 스스로 세우고 실행할 수 있다.

- 🔥 Level 3 : Lecture Note에 있는 주요 개념과 코드를 연결하여 설명할 수 있으며, 이를 바탕으로 코드를 구현하고 도전 과제를 수행할 수 있다.
  - 새로운 데이터에 대하여 타겟과 문제에 적합한 모델을 직접 선택하여 학습할 수 있고, 이 과정에서 Permutation Importance를 통해 중요한 특성만 학습하여 모델 성능을 향상시킬 수 있다.


### 키워드🔑
- 특성중요도
- Mean decrease impurity
- Drop-Column Importance
- Permutation Importance
- eli5


### 새로 배운 개념📑
- Mean decrease impurity
  - 트리 기반 모델의 각 step에서 특정 피쳐에 의해 노드가 분할될 때 감소되는 불순도의 양
  - feature_importances_ 메써드를 사용할 때 계산되는 특성중요도(Feature Importance)가 바로 이것임
  - 빠르고 간편하게 계산이 가능하다는 장점이 있음
  - 단점, 높은 카디널리티에 높은 특성중요도가 부여됨

- Drop-Column Importance
  - 특정한 특성을 제거하고 모델을 학습 한 후, 모든 특성을 사용한 모델의 성능과 비교하여 하락한 성능의 양
  - 각 특성을 제거 할 때마다 재학습을 해야하기 때문에 속도가 느림

- Permutation Importance
  - 전체 특성으로 모델을 학습 한 뒤, 성능을 평가하는 단계에서 각 특성에 노이즈를 주어 해당 특성의 중요도를 인위적으로 낮추어 성능이 얼마나 감소하는지 계산
  - 노이즈를 주는 가장 간단한 방법은 특성값을 섞는 것(Shuffle, Permutation)
  - 장점, 재학습이 필요없음
  - 장점, 모든 모델 사용 가능
  - 장점, high cardinality 특성에 덜 민감함
  - 단점, 강한 상관관계가 있는 특성이 있는 경우 잘못된 계산을 할 수 있음


- black box model : 해석불가능한 ML 모델




<br><br><br><br>

## N232 : Interpretable ML - II
{: style="text-align: center;"}

<br><br><br><br>




### 학습 목표🚩
- 🌱 Level 1 : Lecture Note 에 있는 주요 개념을 설명할 수 있으며 예제 코드를 이해하고 응용하여 과제를 수행할 수 있다.
  - ICE Plot / PDP
    - 특성 중요도와 PDP 간의 차이를 이해하고 목적에 맞게 사용할 수 있다.
    - ICE Plot의 개념을 이해하고 구현 및 해석할 수 있다.
    - PDP의 개념을 이해하고 구현할 수 있으며 PDP의 특징에 유의하여 해석할 수 있다.

  - 모델 해석 범위에 따른 모델 해석 방법
    - Model-Specific과 Model-Agnostic의 차이를 이해하고 예시를 들어 설명할 수 있다.
    - Global과 Local의 차이를 이해하고 예시를 들어 설명할 수 있다.

- 🔝 Level 2 : Lecture Note 에 있는 개념 중 자신이 모르는 것을 구분해 낼 수 있으며 메타인지를 기반으로 자기 학습 계획을 세울 수 있다.
  - 오늘 배운 내용 중 아는 개념과 모르는 개념을 구분해서 readme.md 에 기록할 수 있다.
  → N232 노트 마무리 학습 후 아래 질문에 답해보세요의 질문에 답을 해보고 추가 학습이 필요한 질문을 기록할 수 있다.
  - 이후에 모르는 개념을 학습하기 위해 추가 학습 계획을 스스로 세우고 실행할 수 있다.

- 🔥 Level 3 : Lecture Note에 있는 주요 개념과 코드를 연결하여 설명할 수 있으며, 이를 바탕으로 코드를 구현하고 도전 과제를 수행할 수 있다.
  - 새로운 데이터에 대하여 모델링을 수행하고 PDP를 사용해서 모델을 해석하여 인사이트를 도출할 수 있다.


### 키워드🔑
- 개별 예측
- 평균 예측
- 예측 시각화


### 새로 배운 개념📑
- Individual Conditional Expectation(ICE) Plot
  - 특정 관측치의 특정 특성 값을 변화시킬 때 모델의 예측값이 어떻게 변하는지 시각화
  - 이상치 분석

- Partial Dependence Plot (PDP)
  - 모든 관측치의 특정 특성 값을 변화시킬 때 모델의 예측값이 어떻게 변하는지 시각화
  - 특정 특성에 대한 전체적인 데이터의 추세를 파악


- 머신러닝 모델 해석의 분류  

<div style="text-align : center;">
  <img alt="image" width="80%"
  src="https://www.cognex.com/library/media/blogs/kr-deep-learning-research/iml-methods-plot.jpg?la=ko-kr&hash=9BC879C015B398C7E6C9D4B7FFD4245AA13DC6FB&sc_lang=ko-kr">  
</div> 

- Model-Specific : 해당 모델에 종속
- Model-Agnostic : 모든 모델에 범용적으로 적용 가능
- Local : 특정한 관측치 중심
- Global : 전체 관측치(평균)




<br><br><br><br>

## N233 : ML Problem Framing
{: style="text-align: center;"}

<br><br><br><br>




### 학습 목표🚩
- 🌱 Level 1 : Lecture Note 에 있는 주요 개념을 설명할 수 있으며 예제 코드를 이해하고 응용하여 과제를 수행할 수 있다.
  - 머신러닝 문제의 특성을 이해하고 내가 풀고자 하는 문제에 ML을 적용하는 것이 적합할지 판단할 수 있다.
  - 풀고자 하는 문제와 목적에 맞게 머신러닝 문제(회귀 or 분류)를 정의할 수 있다.
  - 머신러닝 문제의 타겟을 적절히 선택/조작할 수 있다.
  - 정보의 누수(Data Leakage)가 발생하는 경우를 이해하고 이를 예방하기 위한 전처리 과정을 수행할 수 있다.
  - 상황에 맞는 검증지표를 사용할 수 있다.

- 🔝 Level 2 : Lecture Note 에 있는 개념 중 자신이 모르는 것을 구분해 낼 수 있으며 메타인지를 기반으로 자기 학습 계획을 세울 수 있다.
  - 오늘 배운 내용 중 아는 개념과 모르는 개념을 구분해서 readme.md 에 기록할 수 있다.
  → N233 노트 마무리 학습 후 아래 질문에 답해보세요의 질문에 답을 해보고 추가 학습이 필요한 질문을 기록할 수 있다.
  - 이후에 모르는 개념을 학습하기 위해 추가 학습 계획을 스스로 세우고 실행할 수 있다.

- 🔥 Level 3 : Lecture Note에 있는 주요 개념과 코드를 연결하여 설명할 수 있으며, 이를 바탕으로 프로젝트를 기획할 수 있다.


### 키워드🔑
- 머신러닝의 문제
- 정보 누수(Data Leakage)
- 평가지표


### 새로 배운 개념📑
- 정보 누수(Data Leakage)
  - 별다른 작업을 하지 않았음에도 100%에 가까운 일반화 성능을 얻은 경우 정보 누수(Data Leakage)를 의심

- 학습 데이터가 예측 시 못 쓰는 피쳐를 반영하는 경우(Column axis)
  - 학습시 타겟정보를 담고있는 특성으로 학습하는 경우

- 학습 과정에서 평가 데이터의 정보가 활용되는 경우(Row axis)
  - 학습 데이터와 검증, 평가데이터를 완전하게 분리되지 않은 경우




<br><br><br><br>

## N234 : Special Classification Problems
{: style="text-align: center;"}

<br><br><br><br>




### 학습 목표🚩
- 🌱 Level 1 : Lecture Note 에 있는 주요 개념을 설명할 수 있으며 예제 코드를 이해하고 응용하여 과제를 수행할 수 있다.
  - Imbalanced Target
    - 분류 문제의 타겟이 불균형할 때 적절한 평가지표를 사용해서 모델의 성능을 평가할 수 있다.
  - Target Balancing Methods
    - class_weight, undersampling, oversampling 기법을 사용해서 타겟 분포의 균형을 맞춰줄 수 있다.
    - Train 데이터에만 under / oversamping을 적용해야함을 이해하고 구현할 수 있다.

- 🔝 Level 2 : Lecture Note 에 있는 개념 중 자신이 모르는 것을 구분해 낼 수 있으며 메타인지를 기반으로 자기 학습 계획을 세울 수 있다.
  - 오늘 배운 내용 중 아는 개념과 모르는 개념을 구분해서 readme.md 에 기록할 수 있다.
  → N234 노트 마무리 학습 후 아래 질문에 답해보세요의 질문에 답을 해보고 추가 학습이 필요한 질문을 기록할 수 있다.
  - 이후에 모르는 개념을 학습하기 위해 추가 학습 계획을 스스로 세우고 실행할 수 있다.

- 🔥 Level 3 : Lecture Note에 있는 주요 개념과 코드를 연결하여 설명할 수 있으며, 프로젝트에 적용할 수 있다.
  - 프로젝트에 사용할 데이터의 불균형 문제를 진단하고 균형을 맞춰주는 기법을 적용할 수 있다.

- 🚀 Level 4 : Reference 내용을 설명할 수 있고 심화 내용을 이해하기 위해 추가 학습을 진행할 수 있다.
  - 지금까지 배운 선형모델과 트리 기반 모델로 다중 클래스 분류 (Multi-class Classification) 문제를 해결하기 위한 모델링을 수행할 수 있다.


### 키워드🔑
- 타겟불균형, Undersampling, Oversampling, imblearn



### 새로 배운 개념📑
- Imbalanced Target Distribution
  - 분류문제에서 타겟이 불균형할 경우

- Class Weight 사용
  - xgboost.scale_pos_weight 파라미터 : 타겟0 / 타겟1
  - sklearn.class_weight = 'balanced'

- Undersampling 사용
  - imblearn.RandomUnderSampler()

- Oversampling 사용
  - imblearn.SMOTE()

- Oversampling + Undersapmling 사용
  - imblearn.SMOTEENN()
  - imblearn.SMOTETomek()

- 앙상블 기법 사용
  - imblearn.BalancedBaggingClassifier()

- 평가지표는 accuracy, F1, AUC 등을 골고루 보아야 함
  - confusion matrix 확인 추천







<br><br><br><br>  
<center>  
<h1>끝까지 읽어주셔서 감사합니다😉</h1>  
</center>  
<br><br><br><br>  



